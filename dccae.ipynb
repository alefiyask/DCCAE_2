{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><body><H2><u>Implementation of Deep Canonical Correlation AutoEncoders (DCCAE)- Documented\n",
    "</H2><br></body></html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><body><pre>\n",
    "<h3>We have used the following libraries from Pytorch:</h3>\n",
    "           <b>torch</b>: Tensor computation (like NumPy) and has features for Deep neural networks\n",
    "           <b>nn</b>: These are Neural networks implemented in torch\n",
    "           <b>optim</b>: For implementing various optimization algorithms\n",
    "           <b>functional</b>: Applies a 1D convolution over an input signal composed of several input planes</pre><br></body></html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from DCCAE_repo.configuration import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Here we have defined 'create_encoder'  and 'create_decoder' functions with arguments as mentioned in the config file (Parameters of the neural network).\n",
    "This function creates and returns the encoder for the multidimentional training data set<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(config, i):\n",
    "    encoder = config.encoder_models[i](config.hidden_layer_sizes[i], config.input_sizes[i], config.latent_dims).double()\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder(config, i):\n",
    "    decoder = config.decoder_models[i](config.hidden_layer_sizes[i], config.latent_dims, config.input_sizes[i]).double()\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Description of the DCCAE class and Functions:</b>\n",
    "<pre>We have created a class DCCAE to contain our multiviewed vectors (neural networks), the class\n",
    "contains the following functions:\n",
    "This class is the sub class of nn.Module parent class<br>\n",
    "<b>__init__():</b> constructor, Here the parameters for the neural network are initialized as mentioned in the config file\n",
    "<b>encode()</b>: Here the data for the neural networks is provided. This returns a tuple of the value and its enum\n",
    "<b>forward()</b>: Here the data is forwarded to the encoder\n",
    "<b>decode()</b>: Here the data for decoding is provided in recon array. This too returns a tuple like the encode function\n",
    "<b>update_weights()</b>: This function assigns wights to the data in the nn, we have used optimizer to optimize from a vector    of parameters.\n",
    "<b>loss()</b>: Here the net loss from the nn is calculated\n",
    "<b>recon_loss()</b>: Here the losses are reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCCAE(nn.Module):\n",
    "\n",
    "    def __init__(self, config: Config = Config):\n",
    "        super(DCCAE, self).__init__()\n",
    "        views = len(config.encoder_models)\n",
    "        self.encoders = torch.nn.ModuleList([create_encoder(config, i) for i in range(views)])\n",
    "        self.decoders = torch.nn.ModuleList([create_decoder(config, i) for i in range(views)])\n",
    "        self.lam = config.lam\n",
    "        self.objective = config.objective(config.latent_dims)\n",
    "        self.optimizers = [optim.Adam(list(self.encoders[i].parameters()) + list(self.decoders[i].parameters()),\n",
    "                                      lr=config.learning_rate) for i in range(views)]\n",
    "        \n",
    "\n",
    "\n",
    "    def encode(self, *args):\n",
    "        z = []\n",
    "        for i, arg in enumerate(args):\n",
    "            z.append(self.encoders[i](arg))\n",
    "        return tuple(z)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        z = self.encode(*args)\n",
    "        return z\n",
    "\n",
    "    def decode(self, *args):\n",
    "        recon = []\n",
    "        for i, arg in enumerate(args):\n",
    "            recon.append(self.decoders[i](arg))\n",
    "        return tuple(recon)\n",
    "\n",
    "    def update_weights(self, *args):\n",
    "        [optimizer.zero_grad() for optimizer in self.optimizers]\n",
    "        loss = self.loss(*args)\n",
    "        loss.backward()\n",
    "        [optimizer.step() for optimizer in self.optimizers]\n",
    "        return loss\n",
    "\n",
    "    def loss(self, *args):\n",
    "        z = self.encode(*args)\n",
    "        recon = self.decode(*z)\n",
    "        recon_loss = self.recon_loss(args, recon)\n",
    "        return self.lam * recon_loss + self.objective.loss(*z)\n",
    "\n",
    "    @staticmethod\n",
    "    def recon_loss(x, recon):\n",
    "        recons = [F.mse_loss(recon[i], x[i], reduction='sum') for i in range(len(x))]\n",
    "        return torch.stack(recons).sum(dim=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
