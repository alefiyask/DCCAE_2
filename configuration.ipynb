{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Configuration file for defining the multi layered data (neural network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Config class contains the config method that describes the encoding information for the Autorncoders<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b> For this, we require the functionalities of dcca, deep_models and objectives packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DCCAE_repo.dcca\n",
    "import DCCAE_repo.deep_models\n",
    "import DCCAE_repo.objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>config</b> class contains the main encoding parameters and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Defines the basic architecture DCCA, DCCAE, DVCCA\n",
    "        self.method = DCCAE_repo.dcca.DCCA\n",
    "        \n",
    "        # The number of encoding dimensions\n",
    "        self.latent_dims = 2\n",
    "        self.learning_rate = 1e-3\n",
    "        self.epoch_num = 1\n",
    "        self.patience = 0\n",
    "        self.batch_size = 0\n",
    "        self.eps = 1e-9\n",
    "        self.c = 1e-5\n",
    "        \n",
    "        # Updated automatically when using deepwrapper.DeepWrapper\n",
    "        self.input_sizes = None\n",
    "        \n",
    "        # These control the encoder architectures. We need one for each view. Fully connected models provided by default\n",
    "        self.encoder_models = [DCCAE_repo.deep_models.Encoder, DCCAE_repo.deep_models.Encoder]\n",
    "        \n",
    "        # These control the decoder architectures. We need one for each view for using DCCAE. Fully connected models provided by default\n",
    "        self.decoder_models = [DCCAE_repo.deep_models.Decoder, DCCAE_repo.deep_models.Decoder]\n",
    "        \n",
    "        # These are parameters used by DCCAE_repo.deep_models.Encoder\n",
    "        self.hidden_layer_sizes = [[128], [128]]\n",
    "        \n",
    "        # We can choose to use DCCAE_repo.objectives.CCA\n",
    "        self.objective = DCCAE_repo.objectives.CCA\n",
    "        \n",
    "        # We also implement DCCA by non-linear orthogonal iterations (alternating least squares).\n",
    "        self.als = False\n",
    "        self.rho = 0.2\n",
    "\n",
    "        # for DCCAE:\n",
    "        # Weighting of reconstruction vs correlation loss\n",
    "        self.lam = 0.5\n",
    "        \n",
    "        # mu from the original paper controls the weighting of each encoder\n",
    "        self.mu = 0.5\n",
    "\n",
    "        # Not used yet\n",
    "        self.autoencoder = False\n",
    "        self.confound_encoder_models = [DCCAE_repo.deep_models.Encoder]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
